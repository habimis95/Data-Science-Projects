{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('lr_example').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import corr\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark to read in the Ecommerce Customers csv file.\n",
    "data = spark.read.csv('flights.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'mile' to 'km'\n",
    "data = data.withColumn('km', round(data.mile * 1.60934, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "data = data.withColumn('label', (data.delay >= 15).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(data)\n",
    "\n",
    "# Indexer creates a new column with a numeric index values\n",
    "data_indexed = indexer_model.transform(data)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "data_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(data_indexed).transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| null|        6.0|    2.0|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_indexed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assembler object\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = ['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'],\n",
    "    outputCol = 'features') # input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = assembler.transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|km    |label|carrier_idx|org_idx|features                                 |\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "|11 |20 |6  |US     |19    |JFK|2153|9.48  |351     |NA   |3465.0|null |6.0        |2.0    |[11.0,20.0,6.0,6.0,2.0,3465.0,9.48,351.0]|\n",
      "|0  |22 |2  |UA     |1107  |ORD|316 |16.33 |82      |30   |509.0 |1    |0.0        |0.0    |[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |\n",
      "|2  |20 |4  |UA     |226   |SFO|337 |6.17  |82      |-8   |542.0 |0    |0.0        |1.0    |[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pre.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = data_pre.select('features', 'label')\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.na.drop()\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |label|\n",
      "+-----------------------------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |1    |\n",
      "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |0    |\n",
      "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|0    |\n",
      "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |0    |\n",
      "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |1    |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model object\n",
    "logistic = LogisticRegression(featuresCol='features',\n",
    "                      labelCol='label',\n",
    "                      predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this model logisticModel\n",
    "logisticModel = logistic.fit(train_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1698|\n",
      "|    0|       0.0| 2625|\n",
      "|    1|       1.0| 3141|\n",
      "|    0|       1.0| 1980|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a predictions for the testing data and show confusion matrix\n",
    "test_model = logisticModel.transform(test_data)\n",
    "test_model.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = test_model.filter('prediction = 0 and label = prediction').count()\n",
    "TP = test_model.filter('prediction = 1 and label = prediction').count()\n",
    "FN = test_model.filter('prediction = 0 and label != prediction').count()\n",
    "FP = test_model.filter('prediction = 1 and label != prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.61\n",
      "recall   = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall   = {:.2}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.6105463786531131\n"
     ]
    }
   ],
   "source": [
    "print('Acc: ', (TN + TP) / (TN+TP+FN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(test_model,\n",
    "                                              {multi_evaluator.metricName: \"weightedPrecision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6103630501071541"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(test_model,\n",
    "                                {binary_evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6475066523153014"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "logisticModel.save('logisticModel_Flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "# Load model from\n",
    "logisticModel2 = LogisticRegressionModel.load('logisticModel_Flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new values (Assuming select test_data)\n",
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticModel2.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|features                             |rawPrediction                           |probability                             |prediction|\n",
      "+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|(8,[1,5,6,7],[6.0,378.0,21.33,69.0]) |[-1.0700505098348914,1.0700505098348914]|[0.25539347871726,0.7446065212827401]   |1.0       |\n",
      "|(8,[1,5,6,7],[6.0,1291.0,20.0,148.0])|[-1.1526114042830131,1.1526114042830131]|[0.24001242269150957,0.7599875773084904]|1.0       |\n",
      "+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
