{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwC2Nr5RR2LC"
   },
   "source": [
    "# Demo Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awc-2kK0R2LD"
   },
   "source": [
    "### Dataset: flights.csv\n",
    "- You'll build a regression model to predict flight delay or not \n",
    "- With 'mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration' as a predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sdn8c0h0R2LD"
   },
   "source": [
    "First thing to do is start a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "64JV__HcR2LE"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "it0eeUpcR2LH"
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OreDvnvPR2LJ"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sckUTQOsR2LM"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('lr_demo').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UVnE-S3rR2LO"
   },
   "outputs": [],
   "source": [
    "# Use Spark to read flights.csv file.\n",
    "data = spark.read.csv(\"flights.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pz5UpQ9tR2LQ",
    "outputId": "78cb5001-29a7-4890-a378-23f701306901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Schema of the DataFrame\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IsxKkZvnR2LT",
    "outputId": "d4e13952-69ad-4b01-c66d-fecbe4439fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vt0zISVmR2LV",
    "outputId": "9eb7544d-f58e-4688-9d82-6ac54dac84d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(mon=11, dom=20, dow=6, carrier='US', flight=19, org='JFK', mile=2153, depart=9.48, duration=351, delay='NA')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aVW5oJbAR2LY"
   },
   "outputs": [],
   "source": [
    "# for item in data.head():\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Xmgtp7BrR2Lb",
    "outputId": "652fcdb2-b72c-40ca-c34a-84ae5bcf8825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RxJ71KYWR2Ld"
   },
   "outputs": [],
   "source": [
    "# Remove the 'flight' column\n",
    "data = data.drop('flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WMG3SWC_R2Lf",
    "outputId": "e6b2ac56-500e-409a-95be-f35065f5e706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records with missing 'delay' values\n",
    "data.filter('delay IS NULL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HbCunsjhR2Li"
   },
   "outputs": [],
   "source": [
    "# Remove records with missing 'delay' values\n",
    "data = data.filter('delay IS NOT NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "w1aOzJQ8R2Lk",
    "outputId": "5aa6e78f-ecd8-4ae3-bc62-b7d93dfa67d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "data = data.na.drop()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RqURa8-YR2Lm"
   },
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uDUHI8xkR2Lo"
   },
   "outputs": [],
   "source": [
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "data = data.withColumn('km', round(data.mile * 1.60934, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SlikOkPBR2Lr",
    "outputId": "f5648c4d-3a4f-4c58-d7ad-085296ebf4f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|mile|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+\n",
      "| 11| 20|  6|     US|JFK|2153|  9.48|     351|   NA|3465.0| null|\n",
      "|  0| 22|  2|     UA|ORD| 316| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "data = data.withColumn('label', (data.delay >= 15).cast('integer'))\n",
    "# Check first five records\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_TRGWh-R2Lt"
   },
   "source": [
    "## Categories data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-gTwydfvR2Lt"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wrtgPrSDR2Lw"
   },
   "outputs": [],
   "source": [
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(data)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "data_indexed = indexer_model.transform(data)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "data_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(data_indexed).transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "InbXrHLzR2Ly",
    "outputId": "7415b9cd-f306-44c1-be9e-5293bfa97ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|mile|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "| 11| 20|  6|     US|JFK|2153|  9.48|     351|   NA|3465.0| null|        6.0|    2.0|\n",
      "|  0| 22|  2|     UA|ORD| 316| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|\n",
      "|  2| 20|  4|     UA|SFO| 337|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_indexed.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afYvBXQzR2L0"
   },
   "source": [
    "## Setting Up DataFrame for Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ_-3LFKR2L0"
   },
   "source": [
    "## Assembling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0g8J-G4cR2L1"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "C2DCNjCmR2L3",
    "outputId": "a55fd804-4a75-4200-dd7c-f24f5befee6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mon',\n",
       " 'dom',\n",
       " 'dow',\n",
       " 'carrier',\n",
       " 'org',\n",
       " 'mile',\n",
       " 'depart',\n",
       " 'duration',\n",
       " 'delay',\n",
       " 'km',\n",
       " 'label',\n",
       " 'carrier_idx',\n",
       " 'org_idx']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Oy0aQ7v5R2L4"
   },
   "outputs": [],
   "source": [
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'\n",
    "], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "71Zgv3GXR2L7"
   },
   "outputs": [],
   "source": [
    "data_pre = assembler.transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9xzPcDMRR2L9",
    "outputId": "24db9cae-73ae-44ba-9d9d-138071bbe737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |label|\n",
      "+-----------------------------------------+-----+\n",
      "|[11.0,20.0,6.0,6.0,2.0,3465.0,9.48,351.0]|null |\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |1    |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the resulting column\n",
    "data_pre.select('features', 'label').show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RuPfIPrqR2L_",
    "outputId": "234bfc09-36ec-400d-e04b-864967d6d445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "|mon|dom|dow|carrier|org|mile|depart|duration|delay|km    |label|carrier_idx|org_idx|features                                 |\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "|11 |20 |6  |US     |JFK|2153|9.48  |351     |NA   |3465.0|null |6.0        |2.0    |[11.0,20.0,6.0,6.0,2.0,3465.0,9.48,351.0]|\n",
      "|0  |22 |2  |UA     |ORD|316 |16.33 |82      |30   |509.0 |1    |0.0        |0.0    |[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |\n",
      "|2  |20 |4  |UA     |SFO|337 |6.17  |82      |-8   |542.0 |0    |0.0        |1.0    |[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |\n",
      "+---+---+---+-------+---+----+------+--------+-----+------+-----+-----------+-------+-----------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pre.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ohvD2PqmR2MC",
    "outputId": "93751c8f-7ef7-4a14-dd32-659009c82a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = data_pre.select(\"features\",\"label\")\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vgTXYctAR2ME",
    "outputId": "5507bde7-eaae-4135-d08d-f1f2697f547b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47022"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.na.drop()\n",
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1to1rg0xR2MF",
    "outputId": "c12a0b1e-3123-4a26-f1c9-332924a055b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0...|    1|\n",
      "|[2.0,20.0,4.0,0.0...|    0|\n",
      "|[9.0,13.0,1.0,1.0...|    0|\n",
      "|[5.0,2.0,1.0,0.0,...|    0|\n",
      "|[7.0,2.0,6.0,1.0,...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9nsawBjJR2MH"
   },
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BrH9NKivR2MJ",
    "outputId": "9664b98c-36b2-4e8a-bb73-38c3285f070b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             label|\n",
      "+-------+------------------+\n",
      "|  count|             37519|\n",
      "|   mean|0.5122471281217517|\n",
      "| stddev|0.4998566467729511|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ku-q2foZR2MM",
    "outputId": "0e542c7c-6fa0-41f7-f94b-63797818a692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             label|\n",
      "+-------+------------------+\n",
      "|  count|              9503|\n",
      "|   mean|0.5076291697358729|\n",
      "| stddev|0.4999680988764607|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDiQibqRxZcH"
   },
   "source": [
    "# Decision Tree\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier(featuresCol='features',\n",
    "                              labelCol='label',\n",
    "                              predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this tree_model\n",
    "tree_model = tree.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test dataset\n",
    "test_model = tree_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------------------------------------+\n",
      "|label|prediction|probability                            |\n",
      "+-----+----------+---------------------------------------+\n",
      "|1    |1.0       |[0.3672396245618003,0.6327603754381997]|\n",
      "|0    |1.0       |[0.3672396245618003,0.6327603754381997]|\n",
      "|1    |1.0       |[0.3672396245618003,0.6327603754381997]|\n",
      "+-----+----------+---------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect results\n",
    "test_model.select('label', 'prediction', 'probability').show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1224|\n",
      "|    0|       0.0| 2466|\n",
      "|    1|       1.0| 3600|\n",
      "|    0|       1.0| 2213|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "test_model.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = test_model.filter('prediction = 0 and label = prediction').count()\n",
    "TP = test_model.filter('prediction = 1 and label = prediction').count()\n",
    "FN = test_model.filter('prediction = 0 and label != prediction').count()\n",
    "FP = test_model.filter('prediction = 1 and label != prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6383247395559297\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures the proportion of correct predictions\n",
    "print('Accuracy: ', (TN + TP) / (TN+TP+FN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.62\n",
      "recall   = 0.75\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall   = {:.2}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(test_model,\n",
    "                                              {multi_evaluator.metricName: \"weightedPrecision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434233626410526"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(test_model,\n",
    "                                {binary_evaluator.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6445129512018165"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "tree_model.save('tree_model_flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassificationModel\n",
    "# Load model from\n",
    "tree_model2 = DecisionTreeClassificationModel.load('tree_model_flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new values (Assuming select test_data)\n",
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree_model2.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+---------------------------------------+----------+\n",
      "|features                              |rawPrediction   |probability                            |prediction|\n",
      "+--------------------------------------+----------------+---------------------------------------+----------+\n",
      "|(8,[1,5,6,7],[6.0,538.0,20.0,84.0])   |[6495.0,11191.0]|[0.3672396245618003,0.6327603754381997]|1.0       |\n",
      "|(8,[1,5,6,7],[6.0,1366.0,13.17,135.0])|[6495.0,11191.0]|[0.3672396245618003,0.6327603754381997]|1.0       |\n",
      "+--------------------------------------+----------------+---------------------------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(featuresCol='features',\n",
    "                             labelCol='label',\n",
    "                             predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this rfc_model\n",
    "rfc_model = rfc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 20\n",
      "Relative importance of features: (8,[0,1,2,3,4,5,6,7],[0.21332959390852432,0.01820939604960225,0.014906799404443616,0.06302817698402711,0.2507675488599955,0.050950740177925,0.34216746370462287,0.0466402809108592])\n"
     ]
    }
   ],
   "source": [
    "# Find the number of tree and the relative importance of features\n",
    "print('Number of trees:', rfc_model.getNumTrees)\n",
    "print('Relative importance of features:', rfc_model.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test dataset\n",
    "rfc_test_model = rfc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|1    |1.0       |[0.3938817093547602,0.6061182906452398] |\n",
      "|0    |1.0       |[0.35297497107958875,0.6470250289204114]|\n",
      "|1    |1.0       |[0.34245483144831407,0.657545168551686] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect results\n",
    "rfc_test_model.select('label', 'prediction', 'probability').show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1621|\n",
      "|    0|       0.0| 2896|\n",
      "|    1|       1.0| 3203|\n",
      "|    0|       1.0| 1783|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "rfc_test_model.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = test_model.filter('prediction = 0 and label = prediction').count()\n",
    "TP = test_model.filter('prediction = 1 and label = prediction').count()\n",
    "FN = test_model.filter('prediction = 0 and label != prediction').count()\n",
    "FP = test_model.filter('prediction = 1 and label != prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6383247395559297\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures the proportion of correct predictions\n",
    "print('Accuracy: ', (TN + TP) / (TN+TP+FN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "rfc_model.save('rfc_model_flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "|features                              |rawPrediction                          |probability                             |prediction|\n",
      "+--------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "|(8,[1,5,6,7],[6.0,538.0,20.0,84.0])   |[7.877634187095204,12.122365812904796] |[0.3938817093547602,0.6061182906452398] |1.0       |\n",
      "|(8,[1,5,6,7],[6.0,1366.0,13.17,135.0])|[7.0594994215917755,12.940500578408226]|[0.35297497107958875,0.6470250289204114]|1.0       |\n",
      "|(8,[1,5,6,7],[6.0,2411.0,20.68,241.0])|[6.849096628966281,13.150903371033719] |[0.34245483144831407,0.657545168551686] |1.0       |\n",
      "+--------------------------------------+---------------------------------------+----------------------------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "# Load model from\n",
    "rfc_model2 = RandomForestClassificationModel.load('rfc_model_flights_50k')\n",
    "\n",
    "# Predict new values (Assuming select test_data)\n",
    "unlabeled_data = test_data.select('features')\n",
    "\n",
    "predictions = rfc_model2.transform(unlabeled_data)\n",
    "\n",
    "predictions.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol='features',\n",
    "                    labelCol='label',\n",
    "                    predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this gbt_model\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees:  20\n",
      "Relative importance of features: (8,[0,1,2,3,4,5,6,7],[0.19310486189285184,0.16009260469429737,0.15006906228740075,0.08658397782702128,0.16370047680501348,0.06830546520387297,0.13871524602018986,0.03942830526935252])\n"
     ]
    }
   ],
   "source": [
    "# Find the number of trees and the relative importance of features\n",
    "print('Number of trees: ', gbt_model.getNumTrees)\n",
    "print('Relative importance of features:', gbt_model.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test dataset\n",
    "gbt_test_model = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|1    |1.0       |[0.19018799066680808,0.809812009333192] |\n",
      "|0    |1.0       |[0.29952519496746777,0.7004748050325322]|\n",
      "|1    |1.0       |[0.16564957437919892,0.8343504256208011]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect results\n",
    "gbt_test_model.select('label', 'prediction', 'probability').show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1377|\n",
      "|    0|       0.0| 2898|\n",
      "|    1|       1.0| 3447|\n",
      "|    0|       1.0| 1781|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "gbt_test_model.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = test_model.filter('prediction = 0 and label = prediction').count()\n",
    "TP = test_model.filter('prediction = 1 and label = prediction').count()\n",
    "FN = test_model.filter('prediction = 0 and label != prediction').count()\n",
    "FP = test_model.filter('prediction = 1 and label != prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6383247395559297\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures the proportion of correct predictions\n",
    "print('Accuracy: ', (TN + TP) / (TN+TP+FN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "gbt_model.save('gbt_model_flights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------------------------------+----------------------------------------+----------+\n",
      "|features                              |rawPrediction                             |probability                             |prediction|\n",
      "+--------------------------------------+------------------------------------------+----------------------------------------+----------+\n",
      "|(8,[1,5,6,7],[6.0,538.0,20.0,84.0])   |[-0.7243945629611589,0.7243945629611589]  |[0.19018799066680808,0.809812009333192] |1.0       |\n",
      "|(8,[1,5,6,7],[6.0,1366.0,13.17,135.0])|[-0.42477993028121197,0.42477993028121197]|[0.29952519496746777,0.7004748050325322]|1.0       |\n",
      "|(8,[1,5,6,7],[6.0,2411.0,20.68,241.0])|[-0.8083894646854622,0.8083894646854622]  |[0.16564957437919892,0.8343504256208011]|1.0       |\n",
      "+--------------------------------------+------------------------------------------+----------------------------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model from\n",
    "gbt_model2 = GBTClassificationModel.load('gbt_model_flights_50k')\n",
    "\n",
    "# Predict new values (Assuming select test_data)\n",
    "unlabeled_data = test_data.select('features')\n",
    "\n",
    "predictions = gbt_model2.transform(unlabeled_data)\n",
    "\n",
    "predictions.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare 3 model results: Decision Tree, Random Forest, GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "dtc_predictions = tree_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "------------------------------------------------------------\n",
      "A single decision tree has an accuracy of: 63.83%\n",
      "------------------------------------------------------------\n",
      "A random forest ensemble has an accuracy of: 64.18%\n",
      "------------------------------------------------------------\n",
      "An ensemble using GBT has an accuracy of: 66.77%\n"
     ]
    }
   ],
   "source": [
    "print('Results')\n",
    "print('-'*60)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*60)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*60)\n",
    "print('An ensemble using GBT has an accuracy of: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AUC on testing data\n",
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc_2 = evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc_2 = evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc_2 = evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "------------------------------------------------------------\n",
      "A single decision tree has an accuracy of: 64.45%\n",
      "------------------------------------------------------------\n",
      "A random forest ensemble has an accuracy of: 69.05%\n",
      "------------------------------------------------------------\n",
      "An ensemble using GBT has an accuracy of: 73.05%\n"
     ]
    }
   ],
   "source": [
    "print('Results')\n",
    "print('-'*60)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc_2*100))\n",
    "print('-'*60)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc_2*100))\n",
    "print('-'*60)\n",
    "print('An ensemble using GBT has an accuracy of: {0:2.2f}%'.format(gbt_acc_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "afYvBXQzR2L0"
   ],
   "name": "demo_Tree_Method_flights_50K_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
