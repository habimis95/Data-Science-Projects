{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Chap 11 - Demo NLP.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Vv5aigHuY8MX"},"source":["import findspark\n","findspark.init()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71eAbg5sY8Mi"},"source":["import pyspark"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGKcXMGrY8Mj"},"source":["from pyspark import SparkContext\n","from pyspark.conf import SparkConf\n","from pyspark.sql import SparkSession"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgvMV8m1Y8Ml"},"source":["spark = SparkSession.builder.appName('lr_demo').getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4aCUAPsY8Mm"},"source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QENXMxbgY8Mn"},"source":["sentenceDataFrame = spark.createDataFrame([\n","    (0, 'Hi I heard about Spark'),\n","    (1, 'I know Spark can work well with NLP'),\n","    (2, 'Logistic,regression,models,are,supervised')\n","], ['id', 'sentence'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eFZ95_dY8Mo","outputId":"299dc2c4-8406-4dfd-f8c9-7489c854ab3c"},"source":["sentenceDataFrame.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|Hi I heard about ...|\n","|  1|I know Spark can ...|\n","|  2|Logistic,regressi...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MX89gvrsY8Mt"},"source":["## Tokenizer"]},{"cell_type":"code","metadata":{"id":"N_bJ53puY8Mv","outputId":"f21a1542-295a-45e7-bd08-4b0cb85c1c3e"},"source":["tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n","\n","regexTokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')\n","#alternatively, pattern = '\\\\w+', gaps(False)\n","\n","countTokens = udf(lambda words: len(words), IntegerType())\n","\n","tokenized = tokenizer.transform(sentenceDataFrame)\n","tokenized.select('sentence', 'words')\\\n","    .withColumn('tokens', countTokens(col('words'))).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----------------------------------------+--------------------------------------------+------+\n","|sentence                                 |words                                       |tokens|\n","+-----------------------------------------+--------------------------------------------+------+\n","|Hi I heard about Spark                   |[hi, i, heard, about, spark]                |5     |\n","|I know Spark can work well with NLP      |[i, know, spark, can, work, well, with, nlp]|8     |\n","|Logistic,regression,models,are,supervised|[logistic,regression,models,are,supervised] |1     |\n","+-----------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dmHuokT6Y8Mx","outputId":"8244e924-9d4a-41c3-cf7a-6054192c9ffe"},"source":["regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n","regexTokenized.select('sentence', 'words')\\\n","    .withColumn('tokens', countTokens(col('words'))).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----------------------------------------+-----------------------------------------------+------+\n","|sentence                                 |words                                          |tokens|\n","+-----------------------------------------+-----------------------------------------------+------+\n","|Hi I heard about Spark                   |[hi, i, heard, about, spark]                   |5     |\n","|I know Spark can work well with NLP      |[i, know, spark, can, work, well, with, nlp]   |8     |\n","|Logistic,regression,models,are,supervised|[logistic, regression, models, are, supervised]|5     |\n","+-----------------------------------------+-----------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tm0A_uiHY8Mz"},"source":["## StopWordsRemover"]},{"cell_type":"code","metadata":{"id":"nmAa2UlTY8Mz","outputId":"094e589a-e98c-469d-a8e7-1ade7508d7cd"},"source":["from pyspark.ml.feature import StopWordsRemover\n","\n","sentenceData = spark.createDataFrame([\n","    (0, ['I', 'go', 'to', 'school', 'by', 'bus']),\n","    (1, ['Minh', 'has', 'lots', 'of', 'pencils']),    \n","], ['id', 'raw'])\n","\n","remover = StopWordsRemover(inputCol='raw', outputCol='filtered')\n","remover.transform(sentenceData).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+------------------------------+---------------------+\n","|id |raw                           |filtered             |\n","+---+------------------------------+---------------------+\n","|0  |[I, go, to, school, by, bus]  |[go, school, bus]    |\n","|1  |[Minh, has, lots, of, pencils]|[Minh, lots, pencils]|\n","+---+------------------------------+---------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D-K-erBbY8M0"},"source":["## Ngram"]},{"cell_type":"code","metadata":{"id":"5h38cV-jY8M1","outputId":"fe327f34-b338-4824-c1f7-d1aee47f83cc"},"source":["from pyspark.ml.feature import NGram\n","\n","wordDataFrame = spark.createDataFrame([\n","    (0, ['Hi', 'I', 'heard', 'about', 'Spark']),\n","    (1, ['I', 'know', 'Spark' 'can' 'work' 'well' 'with' 'NLP']),\n","    (2, ['Logistic','regression','models','are','supervised'])\n","], ['id', 'words'])\n","\n","ngram = NGram(n = 2, inputCol='words', outputCol='ngrams')\n","\n","ngramDataFrame = ngram.transform(wordDataFrame)\n","ngramDataFrame.select('ngrams').show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------------------------------------------------------------------+\n","|ngrams                                                              |\n","+--------------------------------------------------------------------+\n","|[Hi I, I heard, heard about, about Spark]                           |\n","|[I know, know SparkcanworkwellwithNLP]                              |\n","|[Logistic regression, regression models, models are, are supervised]|\n","+--------------------------------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OwleEBj_Y8M3"},"source":["## TF-IDF"]},{"cell_type":"code","metadata":{"id":"s7bCCwZxY8M3"},"source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQ0ZZRfqY8M4"},"source":["sentenceData = spark.createDataFrame([\n","    (0, 'a b c'),\n","    (0, 'a b c a'),\n","    (1, 'a b d d a c c')], ['label', 'sentence'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvXRqKJ9Y8M4","outputId":"fbea8090-20a2-409d-cc93-c1915cdc6858"},"source":["sentenceData.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+-------------+\n","|label|sentence     |\n","+-----+-------------+\n","|0    |a b c        |\n","|0    |a b c a      |\n","|1    |a b d d a c c|\n","+-----+-------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SelmdpEJY8M5","outputId":"4234f059-c6fd-45bc-e031-e73e3553d538"},"source":["tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n","wordsData = tokenizer.transform(sentenceData)\n","wordsData.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+-------------+---------------------+\n","|label|sentence     |words                |\n","+-----+-------------+---------------------+\n","|0    |a b c        |[a, b, c]            |\n","|0    |a b c a      |[a, b, c, a]         |\n","|1    |a b d d a c c|[a, b, d, d, a, c, c]|\n","+-----+-------------+---------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FO1xYEI8Y8M6","outputId":"ff58f01a-c5c2-46b2-d8c1-436355ecd7d0"},"source":["hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=10)\n","featurizedData = hashingTF.transform(wordsData)\n","featurizedData.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+-------------+---------------------+--------------------------------+\n","|label|sentence     |words                |rawFeatures                     |\n","+-----+-------------+---------------------+--------------------------------+\n","|0    |a b c        |[a, b, c]            |(10,[0,1,2],[1.0,1.0,1.0])      |\n","|0    |a b c a      |[a, b, c, a]         |(10,[0,1,2],[2.0,1.0,1.0])      |\n","|1    |a b d d a c c|[a, b, d, d, a, c, c]|(10,[0,1,2,4],[2.0,1.0,2.0,2.0])|\n","+-----+-------------+---------------------+--------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b7avVpp8Y8M8","outputId":"2744659b-78ec-4e9c-8309-dfac72da7da7"},"source":["idf = IDF(inputCol='rawFeatures', outputCol='features')\n","idfModel = idf.fit(featurizedData)\n","rescaledData = idfModel.transform(featurizedData)\n","\n","rescaledData.select('label', 'features').show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+-----------------------------------------------+\n","|label|features                                       |\n","+-----+-----------------------------------------------+\n","|0    |(10,[0,1,2],[0.0,0.0,0.0])                     |\n","|0    |(10,[0,1,2],[0.0,0.0,0.0])                     |\n","|1    |(10,[0,1,2,4],[0.0,0.0,0.0,1.3862943611198906])|\n","+-----+-----------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mmw1j1geY8M9"},"source":["## CountVectorizer"]},{"cell_type":"code","metadata":{"id":"ymWdZp6FY8M9","outputId":"b69514bd-7e42-4a95-e4fc-9cf049c9f956"},"source":["from pyspark.ml.feature import CountVectorizer\n","# Input data: Each row is a bag of words with a ID\n","df = spark.createDataFrame([\n","     (0, 'a b c'.split(' ')),\n","     (0, 'a b c a'.split(' ')),\n","     (1, 'a b d d a c c'.split(' '))], ['id', 'words'])\n","# fit a CountVectorizerModel from the corpus\n","cv = CountVectorizer(inputCol='words', outputCol='features', vocabSize=4, minDF=1)\n","\n","model = cv.fit(df)\n","result = model.transform(df)\n","result.show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+---------------------+-------------------------------+\n","|id |words                |features                       |\n","+---+---------------------+-------------------------------+\n","|0  |[a, b, c]            |(4,[0,1,2],[1.0,1.0,1.0])      |\n","|0  |[a, b, c, a]         |(4,[0,1,2],[2.0,1.0,1.0])      |\n","|1  |[a, b, d, d, a, c, c]|(4,[0,1,2,3],[2.0,2.0,1.0,2.0])|\n","+---+---------------------+-------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rQcrbxzpY8M_"},"source":[""],"execution_count":null,"outputs":[]}]}