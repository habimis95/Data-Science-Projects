{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local\", appName=\"New Spark Context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PM501-12:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>New Spark Context</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=New Spark Context>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD from a list of words \n",
    "RDD = sc.parallelize([\"Spark\",\"is\",\"a\",\"framework\",\"for\",\"Big Data processing\"])\n",
    "\n",
    "# Print out the type of the created object\n",
    "print(\"The type of RDD is\", type(RDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD1 is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "RDD1 = sc.textFile(\"Cung cap du lieu buoi 2/5000_points.txt\", minPartitions=3)\n",
    "print(\"The type of RDD1 is\", type(RDD1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'664159\\t550946'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD2 is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "RDD2 = sc.textFile(\"hdfs://bigdata.laptrinhpython.net:19000/t8.shakespeare.txt\")\n",
    "print(\"The type of RDD2 is\", type(RDD2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the 100th Etext file presented by Project Gutenberg, and'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD2.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD3 = sc.parallelize(RDD2.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(RDD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the 100th Etext file presented by Project Gutenberg, and'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD3.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 16, 9, 25, 36, 49]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD4 = sc.parallelize([1, 4, 3, 5, 6, 7])\n",
    "RDD_map = RDD4.map(lambda x: x * x)\n",
    "RDD_map.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_filter = RDD4.filter(lambda x: x > 3)\n",
    "numbers_all = RDD_filter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for numb in numbers_all: \n",
    "    print(numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Science', 'Machine', 'Learning', 'Big', 'Data']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_string = sc.parallelize([\"Data Science\", \"Machine Learning\", \"Big Data\"])\n",
    "RDD_flatmap = RDD_string.flatMap(lambda x: x.split(\" \"))\n",
    "RDD_flatmap.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 3, 5, 6, 7, 1, 16, 9, 25, 36, 49]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_union = RDD4.union(RDD_map)\n",
    "RDD_union.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 4, 5, 1, 3, 2, 1, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1 = sc.parallelize([1,2,4,4,5])\n",
    "RDD2 = sc.parallelize([1,3,2,1,2])\n",
    "RDD_union = RDD1.union(RDD2)\n",
    "RDD_union.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Science', 'Machine', 'Learning']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_flatmap.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_flatmap.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_flatmap.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 3, 5, 6, 7]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_reduce = RDD4.reduce(lambda x, y: x + y)\n",
    "RDD_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRDD = sc.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRDD.saveAsTextFile(\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numRDD.coalesce(1).saveAsTextFile(\"number_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pair RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SV001', 'Tran Van An'),\n",
       " ('SV002', 'Nguyen Van Anh'),\n",
       " ('SV003', 'Le Thi Cuc')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pair RDDs from list of key-value tuple\n",
    "my_tuple = [('SV001', 'Tran Van An'),('SV002', 'Nguyen Van Anh'),('SV003', 'Le Thi Cuc')]\n",
    "pairRDD_tuple = sc.parallelize(my_tuple)\n",
    "pairRDD_tuple.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'bonjour'), ('happy', 'heureux'), ('morning', 'matin')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pair RDDs from regular RDDs\n",
    "my_list = ['hello bonjour', 'happy heureux', 'morning matin']\n",
    "regularRDD = sc.parallelize(my_list)\n",
    "pairRDD_RDD = regularRDD.map(lambda s: (s.split(' ')[0], s.split(' ')[1]))\n",
    "pairRDD_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV001 co diem tong la 18\n",
      "SV002 co diem tong la 18\n",
      "SV003 co diem tong la 9\n"
     ]
    }
   ],
   "source": [
    "# reduceByKey(): combine value and key\n",
    "Rdd = sc.parallelize([('SV001',8),('SV002',9),('SV001',10),('SV002',9),('SV003',9)])\n",
    "\n",
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "for num in Rdd_Reduced.collect():\n",
    "    print(\"{} co diem tong la {}\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV003 co diem tong la 9\n",
      "SV002 co diem tong la 18\n",
      "SV001 co diem tong la 18\n"
     ]
    }
   ],
   "source": [
    "# sortByKey(): return a RDD sorted by Key\n",
    "Rdd_Reduced_Sort = Rdd_Reduced.sortByKey(ascending=False)\n",
    "for num in Rdd_Reduced_Sort.collect():\n",
    "    print(\"{} co diem tong la {}\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SV001', 8), ('SV002', 9), ('SV001', 10), ('SV002', 9), ('SV003', 9)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupByKey(): group value by key\n",
    "Rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdd_Group_by = Rdd.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV001 [8, 10]\n",
      "SV002 [9, 9]\n",
      "SV003 [9]\n"
     ]
    }
   ],
   "source": [
    "for mssv, marks in Rdd_Group_by:\n",
    "    print(mssv, list(marks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join(): merge RDD based on its key\n",
    "Rdd_Math = sc.parallelize([('SV001',8),('SV002',9),('SV003',9)])\n",
    "Rdd_English = sc.parallelize([('SV001',9),('SV002',8),('SV003',8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SV002', (9, 8)), ('SV001', (8, 9)), ('SV003', (9, 8))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rdd = Rdd_Math.join(Rdd_English)\n",
    "Rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Action on pair RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SV002', (9, 8)), ('SV001', (8, 9)), ('SV003', (9, 8))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countByKey(): count number of value for each key\n",
    "Rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV002 1\n",
      "SV001 1\n",
      "SV003 1\n"
     ]
    }
   ],
   "source": [
    "for key, val in Rdd.countByKey().items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SV001': 10, 'SV002': 6, 'SV003': 8}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collectAsMap(): return key-value pair in RDD in dictionary format * Note: only the last pair will be returned\n",
    "Rdd = sc.parallelize([('SV001', 8),('SV002', 9),('SV001', 10),('SV002', 6),('SV003', 9),('SV003', 8)])\n",
    "Rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
